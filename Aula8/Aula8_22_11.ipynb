{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+nIIvabuDJ7rbkEQnC6q4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PedroFatec/Processamento-de-Linguagem-Natural-A914-N-D.S.M.-113-20242/blob/main/Aula8/Aula8_22_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aula 08 - Introdução a ML para PLN\n",
        "Aluno: Pedro Henrique Figueira\n",
        "\n",
        "\n",
        "### Fundamento de Machine Learning -> Aplicação Matemática para Fenômenos observáveis\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iTcQZmZ5B36W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O intuito destes códigos são realizar uma análise de sentimentos em resenhas de filmes usando os modelos Naive Bayes Multinomial e SVM. Ele utiliza o dataset movie_reviews da biblioteca NLTK, que contém textos rotulados como positivos ou negativos.\n",
        "\n",
        "Os textos são processados e transformados em vetores numéricos com TF-IDF, enquanto os rótulos são convertidos para valores numéricos. Após dividir os dados em treino e teste, os dois modelos são treinados no conjunto de treino.\n",
        "\n",
        "Por fim, os modelos são avaliados no conjunto de teste, e métricas como precisão e F1-score são exibidas para medir o desempenho de cada um na classificação de sentimentos"
      ],
      "metadata": {
        "id": "o1MGjJp9cPjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 1 - Criar o Corpus\n",
        "corpus = [\n",
        "    (\"Eu amo PLN\", \"positivo\"),  # Exemplo rotulado como positivo\n",
        "    (\"Eu odeio bugs\", \"negativo\"),  # Exemplo rotulado como negativo\n",
        "    (\"Amo resolver problemas\", \"positivo\"),  # Outro exemplo positivo\n",
        "    (\"Odeio erros\", \"negativo\")  # Outro exemplo negativo\n",
        "]\n",
        "# O corpus contém textos de exemplo e suas respectivas classes (positivo ou negativo).\n",
        "\n",
        "# Passo 2 - Processar o Texto\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# Função para preprocessar o texto: remove maiúsculas e divide o texto em palavras\n",
        "def preprocess_text(text):\n",
        "    return re.findall(r'\\b\\w+\\b', text.lower())  # Encontra palavras (sequências de caracteres alfanuméricos)\n",
        "\n",
        "# Processa cada texto do corpus para obter as palavras e mantém a associação com o rótulo\n",
        "processed_corpus = [(preprocess_text(text), label) for text, label in corpus]\n",
        "print(processed_corpus)\n",
        "# Exemplo de saída: [(['eu', 'amo', 'pln'], 'positivo'), ...]\n",
        "\n",
        "# Passo 3 - Calculando probabilidades\n",
        "# Contador para armazenar o número de exemplos por classe\n",
        "class_counts = Counter()\n",
        "# Contador para armazenar o número de ocorrências de cada palavra por classe\n",
        "word_counts = defaultdict(Counter)\n",
        "# Dicionário para armazenar o total de palavras por classe\n",
        "total_words = defaultdict(int)\n",
        "\n",
        "# Itera sobre o corpus processado para calcular as contagens\n",
        "for words, label in processed_corpus:\n",
        "    class_counts[label] += 1  # Incrementa o contador da classe\n",
        "    for word in words:  # Para cada palavra no texto\n",
        "        word_counts[label][word] += 1  # Incrementa a contagem da palavra para a classe\n",
        "        total_words[label] += 1  # Incrementa o total de palavras para a classe\n",
        "\n",
        "# Calcula o total de exemplos no corpus\n",
        "total_examples = sum(class_counts.values())\n",
        "# Calcula as probabilidades a priori de cada classe\n",
        "prior_probabilities = {cls: count / total_examples for cls, count in class_counts.items()}\n",
        "\n",
        "# Função para calcular a probabilidade condicional com suavização de Laplace\n",
        "def conditional_probability(word, label, alpha=1):\n",
        "    return (word_counts[label][word] + alpha) / (total_words[label] + alpha * len(word_counts[label]))\n",
        "\n",
        "# Passo 4 - Classificar um novo Texto\n",
        "# Função para prever a classe de um texto\n",
        "def predict(text):\n",
        "    words = preprocess_text(text)  # Preprocessa o texto\n",
        "    probabilities = {}  # Dicionário para armazenar as probabilidades de cada classe\n",
        "\n",
        "    for label in class_counts.keys():\n",
        "        probabilities[label] = prior_probabilities[label]  # Inicializa com a probabilidade a priori da classe\n",
        "        for word in words:  # Para cada palavra no texto\n",
        "            probabilities[label] *= conditional_probability(word, label)  # Multiplica pela probabilidade condicional\n",
        "    # Retorna a classe com a maior probabilidade e as probabilidades calculadas\n",
        "    return max(probabilities, key=probabilities.get), probabilities\n",
        "\n",
        "# Passo 5 - Teste com um novo texto\n",
        "novo_texto = \"Eu amo resolver bugs\"\n",
        "classe, probs = predict(novo_texto)  # Prediz a classe do novo texto\n",
        "\n",
        "# Exibe os resultados\n",
        "print(f\"Texto: '{novo_texto}'\")\n",
        "print(f\"Classe prevista: '{classe}'\")\n",
        "print(\"Probabilidades:\")\n",
        "for label, prob in probs.items():\n",
        "    print(f\"  {label}: {prob}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpIigtJ4Ndlt",
        "outputId": "eadb59aa-1461-45ce-95b5-acd0549e9ec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['eu', 'amo', 'pln'], 'positivo'), (['eu', 'odeio', 'bugs'], 'negativo'), (['amo', 'resolver', 'problemas'], 'positivo'), (['odeio', 'erros'], 'negativo')]\n",
            "Texto: 'Eu amo resolver bugs'\n",
            "Classe prevista: 'positivo'\n",
            "Probabilidades:\n",
            "  positivo: 0.00040980807321904243\n",
            "  negativo: 0.0003048315805517451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 1: Importação das bibliotecas\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer  # Para transformar textos em vetores numéricos usando TF-IDF\n",
        "from sklearn.svm import SVC  # Para criar o modelo de classificação usando uma Máquina de Vetores de Suporte (SVM)\n",
        "from sklearn.model_selection import train_test_split  # Para dividir os dados em conjuntos de treino e teste\n",
        "from sklearn.metrics import classification_report  # Para avaliar a performance do modelo\n",
        "\n",
        "# Passo 2: Dados Exemplo\n",
        "corpus = [\n",
        "    \"Eu amo PLN\",  # Texto 1\n",
        "    \"Eu odeio bugs\",  # Texto 2\n",
        "    \"Eu amo resolver problemas\",  # Texto 3\n",
        "    \"Odeio erros\",  # Texto 4\n",
        "    \"Amo programação\",  # Texto 5\n",
        "    \"Não gosto de falhas\"  # Texto 6\n",
        "]\n",
        "classes = [\"negativo\", \"negativo\", \"positivo\", \"negativo\", \"positivo\", \"negativo\"]\n",
        "# Cada texto do corpus é associado a uma classe ('positivo' ou 'negativo').\n",
        "\n",
        "# Passo 3: Pré-processamento e vetorização\n",
        "# O TfidfVectorizer transforma os textos do corpus em uma matriz de características numéricas.\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)  # Transforma os textos em vetores numéricos baseados em TF-IDF\n",
        "y = classes  # Alvo das classes\n",
        "\n",
        "# Passo 4: Dividir os dados e Treinar o modelo\n",
        "# Divide os dados em conjuntos de treino e teste.\n",
        "# 70% para treino e 30% para teste. O parâmetro random_state garante reprodutibilidade.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Treinamento do modelo SVM com kernel linear.\n",
        "svm_model = SVC(kernel='linear')  # Define o modelo de SVM com um kernel linear\n",
        "svm_model.fit(X_train, y_train)  # Treina o modelo com os dados de treino\n",
        "\n",
        "# Passo 5: Avaliar o modelo\n",
        "y_pred = svm_model.predict(X_test)  # Realiza previsões no conjunto de teste\n",
        "print(classification_report(y_test, y_pred))  # Exibe o relatório de classificação\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5z94wAHbJqn",
        "outputId": "8ebcfba7-4dab-413d-f940-8d0ca0bc1ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo       1.00      0.50      0.67         2\n",
            "    positivo       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.50      0.25      0.33         2\n",
            "weighted avg       1.00      0.50      0.67         2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 1: Importar Bibliotecas\n",
        "import nltk  # Biblioteca para processamento de linguagem natural\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer  # Para transformar texto em vetores numéricos (TF-IDF)\n",
        "from sklearn.model_selection import train_test_split  # Para dividir os dados em treino e teste\n",
        "from sklearn.naive_bayes import MultinomialNB  # Classificador Naive Bayes Multinomial\n",
        "from sklearn.svm import SVC  # Classificador baseado em Máquinas de Vetores de Suporte (SVM)\n",
        "from sklearn.metrics import classification_report  # Para avaliar a performance do modelo\n",
        "from sklearn.preprocessing import LabelEncoder  # Para codificar rótulos em valores numéricos\n",
        "\n",
        "# Baixar o dataset de exemplo\n",
        "nltk.download('movie_reviews')  # Faz o download do dataset \"movie_reviews\" da biblioteca NLTK\n",
        "from nltk.corpus import movie_reviews  # Importa o dataset de resenhas de filmes\n",
        "\n",
        "# Passo 2: Preparação dos dados\n",
        "# Coleta de textos e classes do dataset\n",
        "documents = [(\" \".join(movie_reviews.words(fileid)), category)  # Junta todas as palavras de um texto\n",
        "             for category in movie_reviews.categories()  # Para cada categoria (positivo/negativo)\n",
        "             for fileid in movie_reviews.fileids(category)]  # Para cada arquivo associado à categoria\n",
        "\n",
        "# Separar textos e rótulos em listas distintas\n",
        "texts, labels = zip(*documents)\n",
        "\n",
        "# Transformar rótulos (positivo/negativo) em valores numéricos (0 e 1)\n",
        "label_encoder = LabelEncoder()  # Instancia o codificador de rótulos\n",
        "labels = label_encoder.fit_transform(labels)  # Codifica os rótulos como números\n",
        "\n",
        "# Dividir os dados em conjuntos de treino (70%) e teste (30%)\n",
        "texts_train, texts_test, labels_train, labels_test = train_test_split(\n",
        "    texts, labels, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Passo 3: Representação do texto com TF-IDF\n",
        "# Criar o vetorizador TF-IDF com limite de 5.000 palavras mais frequentes\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "# Ajustar e transformar os textos de treino em vetores numéricos\n",
        "X_train = vectorizer.fit_transform(texts_train)\n",
        "# Transformar os textos de teste usando o mesmo vetorizador\n",
        "X_test = vectorizer.transform(texts_test)\n",
        "\n",
        "# Passo 4: Treinar os modelos\n",
        "# Treinar o modelo Naive Bayes Multinomial\n",
        "nb_model = MultinomialNB()  # Instancia o modelo\n",
        "nb_model.fit(X_train, labels_train)  # Treina o modelo com os dados de treino\n",
        "\n",
        "# Fazer predições com o modelo Naive Bayes\n",
        "nb_predictions = nb_model.predict(X_test)\n",
        "\n",
        "# Treinar o modelo SVM com kernel linear\n",
        "svm_model = SVC(kernel='linear')  # Instancia o modelo SVM com kernel linear\n",
        "svm_model.fit(X_train, labels_train)  # Treina o modelo com os dados de treino\n",
        "\n",
        "# Fazer predições com o modelo SVM\n",
        "svm_predictions = svm_model.predict(X_test)\n",
        "\n",
        "# Passo 5: Avaliação dos modelos\n",
        "# Avaliação do Naive Bayes\n",
        "print(\"Naive Bayes Performance:\")\n",
        "print(classification_report(labels_test, nb_predictions, target_names=label_encoder.classes_))\n",
        "\n",
        "# Avaliação do SVM\n",
        "print(\"SVM Performance:\")\n",
        "print(classification_report(labels_test, svm_predictions, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWR15bKebOXj",
        "outputId": "fa2ec65c-6fc0-41a2-8e9a-3a42c5671ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.79      0.84      0.81       302\n",
            "         pos       0.82      0.77      0.80       298\n",
            "\n",
            "    accuracy                           0.80       600\n",
            "   macro avg       0.80      0.80      0.80       600\n",
            "weighted avg       0.80      0.80      0.80       600\n",
            "\n",
            "SVM Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.82      0.80      0.81       302\n",
            "         pos       0.81      0.82      0.81       298\n",
            "\n",
            "    accuracy                           0.81       600\n",
            "   macro avg       0.81      0.81      0.81       600\n",
            "weighted avg       0.81      0.81      0.81       600\n",
            "\n"
          ]
        }
      ]
    }
  ]
}