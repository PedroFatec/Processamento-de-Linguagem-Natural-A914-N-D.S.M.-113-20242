{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMp7go4fgKMvmSstoZrg4hz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PedroFatec/Processamento-de-Linguagem-Natural-A914-N-D.S.M.-113-20242/blob/main/Aula4_29_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aula 4 - Limpeza de dados textuais\n",
        "## 4.1 Normalização de texto e Remoção de Ruído\n",
        "\n",
        "*Remover caracteres especiais, pontuações, e normalizar o uso de letras maiúsculas e minúsculas*\n",
        "\n",
        "Aluno: Pedro Henrique Figueira - DSM 6º SEMESTRE"
      ],
      "metadata": {
        "id": "M5jXavv9LSLj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ndsPoenYK8rf"
      },
      "outputs": [],
      "source": [
        "# Biblioteca re traz as funcionalidades para expressões regulares\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Texto original contendo pontuações, símbolos especiais e letras maiúsculas\n",
        "original = 'olá!! Este é um exemplo de texto, com várias PONTUAÇÕES, símbolos #especiais, e Letras maiúsculas.'\n",
        "\n",
        "# Limpeza do texto: remove todos os caracteres que não sejam letras ou espaços\n",
        "texto_limpo = re.sub(r'[^A-Za-zÀ-ÿ\\s]', '', original)\n",
        "# Explicação:\n",
        "# - `re.sub`: Substitui partes do texto com base em um padrão.\n",
        "# - `[^A-Za-zÀ-ÿ\\s]`: Expressão regular que seleciona qualquer caractere que:\n",
        "#   - Não seja uma letra (maiúscula ou minúscula) no alfabeto inglês (`A-Za-z`).\n",
        "#   - Não seja uma letra com acento (`À-ÿ`) para suportar idiomas com caracteres especiais.\n",
        "#   - Não seja um espaço (`\\s`).\n",
        "# - Substitui os caracteres selecionados por uma string vazia `''`.\n",
        "\n",
        "# Normalização do texto: converte todo o texto para letras minúsculas\n",
        "texto_normalizado = texto_limpo.lower()\n",
        "# Explicação:\n",
        "# - `.lower()`: Converte todas as letras maiúsculas do texto para minúsculas.\n",
        "\n",
        "# Exibe o texto original\n",
        "print(f'Texto original: {original}')\n",
        "\n",
        "# Exibe o texto após a limpeza\n",
        "print(f'\\nTexto limpo: {texto_limpo}')\n",
        "\n",
        "# Exibe o texto após a normalização\n",
        "print(f'\\nTexto normalizado: {texto_normalizado}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXvnBHFULpt_",
        "outputId": "9404ef10-7109-453b-c3b9-8e7f6ac3933a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto original: olá!! Este é um exemplo de texto, com várias PONTUAÇÕES, símbolos #especiais, e Letras maiúsculas.\n",
            "\n",
            "Texto limpo: olá Este é um exemplo de texto com várias PONTUAÇÕES símbolos especiais e Letras maiúsculas\n",
            "\n",
            "Texto normalizado: olá este é um exemplo de texto com várias pontuações símbolos especiais e letras maiúsculas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa a biblioteca NLTK e a função word_tokenize, que realiza a tokenização de texto\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Faz o download do recurso 'punkt', necessário para a tokenização de palavras\n",
        "nltk.download('punkt_tab')  # O 'punkt_tab' é um conjunto de dados que contém um modelo para tokenização\n",
        "\n",
        "# Texto já normalizado (completo do código anterior)\n",
        "texto_normalizado = 'olá este é um exemplo de texto com várias pontuações símbolos especiais e letras maiúsculas'\n",
        "\n",
        "# Realiza a tokenização do texto, separando-o em palavras (tokens)\n",
        "tokens = word_tokenize(texto_normalizado)\n",
        "\n",
        "# Exibe a lista de tokens (palavras separadas)\n",
        "print(tokens)\n",
        "\n",
        "# Exibe a quantidade de tokens (número de palavras)\n",
        "print(len(tokens))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsVAFp-KLvfM",
        "outputId": "618dcaf3-d806-44c4-aaf2-22128107d076"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['olá', 'este', 'é', 'um', 'exemplo', 'de', 'texto', 'com', 'várias', 'pontuações', 'símbolos', 'especiais', 'e', 'letras', 'maiúsculas']\n",
            "15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.3 Remoção de Stopwords\n",
        "*Stopwords são palavras de pouco valor semântico (como \"de\", \"a\", \"o\") que podem ser removidas para simplificar o texo*"
      ],
      "metadata": {
        "id": "VN0wnF6OLz8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa a função stopwords do NLTK\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Faz o download do recurso stopwords (palavras comuns, irrelevantes para a análise)\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Carrega o conjunto de stopwords em português\n",
        "stopwords_pt = set(stopwords.words('portuguese'))\n",
        "\n",
        "# Filtra os tokens removendo as stopwords\n",
        "token_sem_stopwords = [palavra for palavra in tokens if palavra.lower() not in stopwords_pt]\n",
        "\n",
        "# Exibe os tokens sem stopwords\n",
        "print(token_sem_stopwords)\n",
        "\n",
        "# Exibe o número de tokens após a remoção das stopwords\n",
        "print(len(token_sem_stopwords))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfGAn8Y4L4t0",
        "outputId": "a45c1e77-4e56-43f7-de3b-2caa7e8b0761"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['olá', 'exemplo', 'texto', 'várias', 'pontuações', 'símbolos', 'especiais', 'letras', 'maiúsculas']\n",
            "9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.4 Stemming e Lemalização\n",
        "*Stemming reduz as palavras às suas raízes (ou radicais);*\n",
        "* Lematização normaliza as palavras para suas formas base, levando em conta contexto e gramática."
      ],
      "metadata": {
        "id": "wG4WgfjSL_8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa o stemmer RSLP (Recursos de Stemmer para o Português) do NLTK\n",
        "from nltk.stem import RSLPStemmer\n",
        "\n",
        "# Faz o download do recurso RSLP, necessário para o stemmer\n",
        "nltk.download('rslp')\n",
        "\n",
        "# Cria uma instância do stemmer para o idioma português\n",
        "stemmer = RSLPStemmer()\n",
        "\n",
        "# Aplica o stemming nas palavras restantes (sem stopwords)\n",
        "stemming = [stemmer.stem(palavra) for palavra in token_sem_stopwords]\n",
        "\n",
        "# Exibe as palavras após o processo de stemming\n",
        "print(stemming)\n"
      ],
      "metadata": {
        "id": "ztBDr28NL8ZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.5 Utilizando todo o processo de hoje"
      ],
      "metadata": {
        "id": "QMGngOZEMNPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import re\n",
        "\n",
        "# Download dos recursos do NLTK (se necessário)\n",
        "nltk.download('punkt')  # Pacote necessário para tokenização\n",
        "nltk.download('stopwords')  # Pacote necessário para stopwords\n",
        "\n",
        "# Texto de exemplo\n",
        "texto = \"Este é um exemplo de texto com muitas palavras, algumas repetidas outra @não, e pontuação, símbolos #especiais, e Letras maiúsculas.\"\n",
        "\n",
        "# Limpeza de ruídos e normalização\n",
        "texto_limpo = re.sub(r'[^a-zA-Z]', ' ', texto)  # Remove tudo que não for letra e substitui por espaços\n",
        "texto_lower = texto_limpo.lower()  # Converte o texto para minúsculas\n",
        "\n",
        "# Tokenização\n",
        "tokens = nltk.word_tokenize(texto_lower)  # Divide o texto em palavras (tokens)\n",
        "\n",
        "# Remoção de stopwords\n",
        "stop_words = set(stopwords.words('portuguese'))  # Carrega as stopwords em português\n",
        "palavras_filtradas = [palavra for palavra in tokens if palavra not in stop_words]  # Remove as stopwords\n",
        "\n",
        "# Stemming\n",
        "stemmer = PorterStemmer()  # Instancia o stemmer (utiliza o modelo de inglês, mas pode ser usado com português limitado)\n",
        "palavras_stemizadas = [stemmer.stem(palavra) for palavra in palavras_filtradas]  # Aplica o stemming nas palavras filtradas\n",
        "\n",
        "# Impressão do resultado final\n",
        "print(palavras_stemizadas)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osgLSUJCMO5i",
        "outputId": "c83aa017-a405-4536-8ed1-64ff220e1f15"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['exemplo', 'texto', 'muita', 'palavra', 'alguma', 'repetida', 'outra', 'n', 'pontua', 's', 'mbolo', 'especiai', 'letra', 'mai', 'scula']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}